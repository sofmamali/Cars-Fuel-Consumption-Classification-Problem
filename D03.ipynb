{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kikifana/Team_1_WeLead/blob/main/D03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import os\n",
        "\n",
        "# Create directory for saving plots if it doesn't exist\n",
        "plot_dir = \"classification_results\"\n",
        "os.makedirs(plot_dir, exist_ok=True)\n",
        "\n",
        "def evaluate_and_plot_model(model, X_train, X_test, y_train, y_test, dataset_type):\n",
        "\n",
        "    print(f\"\\n Training {model.__class__.__name__} on {dataset_type}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    precision = precision_score(y_test, y_pred_test, average=\"weighted\")\n",
        "    recall = recall_score(y_test, y_pred_test, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred_test, average=\"weighted\")\n",
        "\n",
        "\n",
        "    print(f\"\\n {model.__class__.__name__} Performance ({dataset_type}):\")\n",
        "    print(f\" Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\" Precision: {precision:.4f}\")\n",
        "    print(f\" Recall:    {recall:.4f}\")\n",
        "    print(f\" F1 Score:  {f1:.4f}\")\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_test)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_test))\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    disp.plot(cmap=\"Blues\", values_format=\".0f\")\n",
        "    plt.title(f\"Confusion Matrix - {model.__class__.__name__} ({dataset_type})\")\n",
        "\n",
        "\n",
        "    cm_path = os.path.join(plot_dir, f\"confusion_matrix_{model.__class__.__name__}_{dataset_type}.png\")\n",
        "    plt.savefig(cm_path, dpi=300)\n",
        "    print(f\" Confusion matrix saved: {cm_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"Model\": model.__class__.__name__,\n",
        "        \"Dataset\": dataset_type,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "8HElksDuJHGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "models = {\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM\": SVC(C=1, gamma=0.01, kernel='rbf', probability=True),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=600, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"LogReg\": LogisticRegression(max_iter=200, random_state=42)\n",
        "}\n",
        "results = []\n",
        "datasets = {\n",
        "    \"Manual Clustering (Standard)\": (X_train_manual_std, X_test_manual_std, y_train_manual_std, y_test_manual_std),\n",
        "    \"KMeans Clustering (Standard)\": (X_train_kmeans_std, X_test_kmeans_std, y_train_kmeans_std, y_test_kmeans_std),\n",
        "    \"Manual Clustering (MinMax)\": (X_train_manual_mm, X_test_manual_mm, y_train_manual_mm, y_test_manual_mm),\n",
        "    \"KMeans Clustering (MinMax)\": (X_train_kmeans_mm, X_test_kmeans_mm, y_train_kmeans_mm, y_test_kmeans_mm)\n",
        "}\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    for dataset_type, (X_train, X_test, y_train, y_test) in datasets.items():\n",
        "        result = evaluate_and_plot_model(model, X_train, X_test, y_train, y_test, dataset_type)\n",
        "        results.append(result)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lxfby9P1JHsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import pandas as pd\n",
        "X = X_train_kmeans_std\n",
        "y = y_train_kmeans_std\n",
        "\n",
        "def evaluate_models_with_cv(models, X, y, cv_folds=5):\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n Evaluating {name} with {cv_folds}-fold Cross-Validation...\")\n",
        "        accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy').mean()\n",
        "        precision = cross_val_score(model, X, y, cv=skf, scoring='precision_weighted').mean()\n",
        "        recall = cross_val_score(model, X, y, cv=skf, scoring='recall_weighted').mean()\n",
        "        f1 = cross_val_score(model, X, y, cv=skf, scoring='f1_weighted').mean()\n",
        "\n",
        "        print(f\" {name} Performance (Cross-Validation):\")\n",
        "        print(f\" Accuracy:  {accuracy:.4f}\")\n",
        "        print(f\" Precision: {precision:.4f}\")\n",
        "        print(f\" Recall:    {recall:.4f}\")\n",
        "        print(f\" F1 Score:  {f1:.4f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"CV Accuracy\": accuracy,\n",
        "            \"CV Precision\": precision,\n",
        "            \"CV Recall\": recall,\n",
        "            \"CV F1 Score\": f1\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "cv_results = evaluate_models_with_cv(models, X, y, cv_folds=5)\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "display(cv_results_df)\n"
      ],
      "metadata": {
        "id": "LOD2rz91JJ3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rf_selector = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf_selector.fit(X_train_kmeans_std, y_train_kmeans_std)\n",
        "feature_importance = rf_selector.feature_importances_\n",
        "features = X_train_kmeans_std.columns\n",
        "sorted_idx = np.argsort(feature_importance)[::-1]\n",
        "top_features = [features[i] for i in sorted_idx[:5]]\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.barh(np.array(features)[sorted_idx][:5], feature_importance[sorted_idx][:5])\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"Top 5 Important Features (Random Forest)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Selected Top 5 Features: {top_features}\")"
      ],
      "metadata": {
        "id": "Ok4YSb64JOZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_top5 = X_train_kmeans_std[top_features]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_top5, y_train_kmeans_std, test_size=0.2, random_state=42, stratify=y_train_kmeans_std)\n",
        "\n",
        "rf_top5 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf_top5.fit(X_train, y_train)\n",
        "y_pred_test = rf_top5.predict(X_test)\n",
        "\n",
        "accuracy_top5 = accuracy_score(y_test, y_pred_test)\n",
        "print(f\" Random Forest Accuracy with Top 5 Features: {accuracy_top5:.4f}\")"
      ],
      "metadata": {
        "id": "XmV9TBrsJQ9R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}